{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeNewsDetection_Glove_FFNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmat/fakenewsdetection/blob/main/FakeNewsDetection_Glove_FFNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY7z2AWVqqQS",
        "outputId": "5fd216a0-34de-4dfe-bc83-ebe2e09798b4"
      },
      "source": [
        "!pip install torchtext==0.8.0\n",
        "!pip install torch==1.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/23/8499af6d9c22b29b01f66a2c11d38ce71cd1cafa2655913c29818ed4a00f/torchtext-0.8.0-cp36-cp36m-manylinux1_x86_64.whl (6.9MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (1.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.8.0) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.7.0\n",
            "    Uninstalling torchtext-0.7.0:\n",
            "      Successfully uninstalled torchtext-0.7.0\n",
            "Successfully installed torchtext-0.8.0\n",
            "Collecting torch==1.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/2a/58f8078744e0408619c63148f7a2e8e48cf007e4146b74d4bb67c56d161b/torch-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (776.7MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7MB 20kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7) (0.16.0)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.6.0\n",
            "    Uninstalling torch-1.6.0:\n",
            "      Successfully uninstalled torch-1.6.0\n",
            "Successfully installed torch-1.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfR9Mim9reIe"
      },
      "source": [
        "# For local run\n",
        "data_path = 'data/'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9NutMxSzHPw",
        "outputId": "7ffcd248-027a-4d55-cd06-a8f06bb136e8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/My Drive/SML/fake news detection/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp2KO5KPWRU8"
      },
      "source": [
        "# Libraries\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "#deal with tensors\n",
        "import torch   \n",
        "\n",
        "#handling text data\n",
        "from torchtext import data \n",
        "\n",
        "# Evaluation\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "import seaborn as sns"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge5pwMsoJVjt"
      },
      "source": [
        "#Reproducing same results\n",
        "SEED = 2019\n",
        "\n",
        "#Torch\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "#Cuda algorithms\n",
        "torch.backends.cudnn.deterministic = True  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf6koevxtIsF"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = 'cpu'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvxcOiKB2mwP",
        "outputId": "c72f9abb-12ac-45c4-8367-8f05b79e3ee1"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec 18 00:05:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    24W / 300W |     10MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3OmSuBlURs-"
      },
      "source": [
        "import string\n",
        "def remove_punctuation(x):\n",
        "  aux = ''.join(ch for ch in x if ch not in set(string.punctuation))\n",
        "  return aux"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaAKKFFRUzTy"
      },
      "source": [
        "# load the training and testing data\n",
        "data_train = pd.read_csv(data_path + 'fnn_train.csv')\n",
        "data_test = pd.read_csv(data_path + 'fnn_test.csv')\n",
        "data_val = pd.read_csv(data_path + 'fnn_dev.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZlj78a8VsuI"
      },
      "source": [
        "# convert the data labels into categorical variables (real = 0, fake = 1)\n",
        "data_train[\"label_fnn\"] = data_train[\"label_fnn\"].replace(\"real\",0)\n",
        "data_train[\"label_fnn\"] = data_train[\"label_fnn\"].replace(\"fake\",1)\n",
        "data_test[\"label_fnn\"] = data_test[\"label_fnn\"].replace(\"real\",0)\n",
        "data_test[\"label_fnn\"] = data_test[\"label_fnn\"].replace(\"fake\",1)\n",
        "data_val[\"label_fnn\"] = data_val[\"label_fnn\"].replace(\"real\",0)\n",
        "data_val[\"label_fnn\"] = data_val[\"label_fnn\"].replace(\"fake\",1)\n",
        "\n",
        "data_train = data_train.drop(\"date\", axis=1)\n",
        "data_test = data_test.drop(\"date\", axis=1)\n",
        "data_val = data_val.drop(\"date\", axis=1)\n",
        "data_train = data_train.drop([\"speaker\"],axis=1)\n",
        "data_test = data_test.drop([\"speaker\"],axis=1)\n",
        "data_val = data_val.drop([\"speaker\"],axis=1)\n",
        "data_train_csv = data_train.drop([\"sources\"],axis=1)\n",
        "data_test_csv = data_test.drop([\"sources\"],axis=1)\n",
        "data_val_csv = data_val.drop([\"sources\"],axis=1)\n",
        "data_train_csv = data_train_csv.rename(columns={\"fullText_based_content\": \"text\",\"label_fnn\": \"label\"}, errors=\"raise\")\n",
        "data_test_csv = data_test_csv.rename(columns={\"fullText_based_content\": \"text\",\"label_fnn\": \"label\"}, errors=\"raise\")\n",
        "data_val_csv = data_val_csv.rename(columns={\"fullText_based_content\": \"text\",\"label_fnn\": \"label\"}, errors=\"raise\")\n",
        "\n",
        "#Remove punctuations\n",
        "data_train_csv['text'] = data_train_csv['text'].apply(remove_punctuation)\n",
        "data_test_csv['text'] = data_test_csv['text'].apply(remove_punctuation)\n",
        "data_val_csv['text'] = data_val_csv['text'].apply(remove_punctuation)\n",
        "\n",
        "data_train_csv.to_csv(data_path + r'fnn_train_clean.csv', index = False)\n",
        "data_test_csv.to_csv(data_path + r'fnn_test_clean.csv', index = False)\n",
        "data_val_csv.to_csv(data_path + r'fnn_val_clean.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCHj8215KL3G",
        "outputId": "d73b40d5-cf0b-4ee1-9662-b195bc395416"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfkyvYbvuvQU"
      },
      "source": [
        "\n",
        "LABEL = data.LabelField(dtype = torch.float) \n",
        "#For LSTM\n",
        "TEXT = data.Field(tokenize='spacy', include_lengths=True, batch_first=True, lower=True,  stop_words = stop_words)\n",
        "\n",
        "#For NN with Bigram\n",
        "# TEXT = data.Field(tokenize='spacy', lower=True, preprocessing = generate_bigrams,  stop_words = stop_words)\n",
        "\n",
        "fields = [('id:',None), ('statement:',None), ('paragraph_based_content',None),\n",
        "      ('text', TEXT),('label',LABEL)]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmG5JnzBv3cn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c12db2-dfba-498d-edc2-5978ea2c88d5"
      },
      "source": [
        "news_data = data.TabularDataset(\n",
        "        path= data_path+ \"fnn_train_clean.csv\", \n",
        "        format=\"CSV\", \n",
        "        fields=fields,\n",
        "        skip_header=True)\n",
        "\n",
        "print(vars(news_data.examples[1]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['supreme', 'court', 'justices', 'embarked', 'three', 'days', 'oral', 'arguments', 'historic', 'lawsuit', 'health', 'care', 'law', 'gov', 'rick', 'scott', 'went', 'national', 'tv', 'media', 'blitz', 'said', 'one', 'regurgitated', 'falsehoods', 'health', 'care', 'debate', '\\n', 'ran', 'campaign', 'getting', 'state', 'back', 'work', 'biggest', 'jobkiller', 'ever', 'said', 'fox', 'friends', 'march', '26', '2012', 'mean', 'think', 'government', 'ca', 'n’t', 'buy', 'health', 'care', 'cheaper', 'anybody', 'else', 'unbelievable', 'penalties', 'go', '\\n', 'big', 'jobkiller', 'cost', 'much', 'said', '\\n', 'politifact', 'examined', 'similar', 'claims', 'law', '’s', 'jobkilling', 'effect', 'house', 'republican', 'leader', 'eric', 'cantor', ' ', 'us', 'chamber', 'commerce', 'former', 'us', 'senate', 'candidate', 'former', 'florida', 'house', 'majority', 'leader', 'adam', 'hasner', ' ', 'none', 'fared', 'well', 'truthometer', '\\n', 'wanted', 'rule', 'scott', '’s', 'statement', 'given', 'renewed', 'debate', 'law', '’ll', 'explain', 'examined', 'jobkilling', 'rhetoric', 'past', 'getting', 'around', 'scott', 'specifically', '\\n', 'none', 'folks', 'made', 'claim', 'could', 'back', 'valid', 'projections', 'job', 'losses', 'instead', 'presented', 'partisan', 'reports', 'skewed', 'interpretations', 'independent', 'reports', 'evidence', '\\n', 'one', 'republican', 'document', 'obamacare', 'budgetbusting', 'jobkilling', 'health', 'care', 'law', 'claimed', 'independent', 'analyses', 'determined', 'health', 'care', 'law', 'cause', 'significant', 'job', 'losses', 'us', 'economy', 'cites', '2010', 'report', 'cbo', 'analyzes', 'impact', 'legislation', 'allegedly', 'determined', 'law', 'would', 'lead', 'roughly', '650000', 'lost', 'jobs', '\\n', 'report', 'n’t', 'say', '\\n', 'said', 'reduction', 'amount', 'labor', 'economy', 'would', 'roughly', 'half', 'percent', ' ', 'onerous', 'regulation', 'workers', 'around', 'retirement', 'age', 'may', 'decide', 'stop', 'working', 'earlier', 'planned', 'report', 'states', 'pointing', 'affordability', 'insurance', 'offered', 'outside', 'workplace', '\\n', 'report', 'says', 'law', 'may', 'also', 'mean', 'people', 'seek', 'jobs', 'medicaid', 'expansion', 'allows', 'lowincome', 'people', 'work', 'still', 'qualify', 'program', '\\n', 'cbo', 'highlight', 'part', 'law', 'likely', 'lead', 'lost', 'jobs', 'requirement', 'businesses', '50', 'workers', 'pay', 'fee', 'offer', 'health', 'insurance', 'plan', 'offer', 'falls', 'short', 'criteria', 'least', 'one', 'employee', 'receives', 'subsidy', 'tobecreated', 'insurance', 'exchange', '\\n', 'fee', 'cbo', 'states', 'passed', 'employees', 'reduced', 'wages', 'compensation', 'businesses', 'pay', 'chunk', 'employees', 'minimum', 'wage', '’s', 'inevitable', 'take', 'fewer', 'lowwage', 'workers', 'may', 'also', 'respond', 'hiring', 'parttime', 'seasonal', 'employees', '\\n', '’s', 'specific', 'gets', 'cbo', '’s', 'update', 'take', 'time', 'assess', 'effects', 'law', 'parts', 'wo', 'n’t', 'implemented', 'another', 'couple', 'years', '\\n', 'another', 'source', 'republicans', 'used', 'backup', 'pretty', 'irrelevant', 'national', 'association', 'independent', 'business', 'said', '2009', 'report', 'impact', 'provision', 'requiring', 'businesses', 'offer', 'insurance', 'would', 'lead', 'elimination', '16', 'million', 'jobs', 'twothirds', 'would', 'small', 'business', 'blanket', 'employer', 'mandate', 'make', 'final', 'law', 'exempts', 'companies', '50', 'fewer', 'employees', 'mandate', '\\n', 'nfib', 'produced', 'recent', 'study', 'november', '2011', 'blasting', 'another', 'part', 'law', 'escalating', 'annual', 'fee', 'starting', '2014', 'health', 'insurance', 'sector', 'group', 'says', 'passed', 'businesses', 'increased', 'premiums', '\\n', 'requirement', 'lobbying', 'group', 'calls', 'health', 'insurance', 'tax', 'would', 'lead', 'lost', 'privatesector', 'jobs', '125000', '249000', '2010', 'group', 'said', 'job', 'losses', 'would', 'total', '4700', '2021', 'florida', '\\n', '’ve', 'found', 'problems', 'nfib', 'research', 'past', 'stories', 'starters', '’s', 'really', 'independent', 'ideological', 'sense', 'lobbying', 'group', 'opposes', 'policy', 'places', 'financial', 'burden', 'business', 'sued', 'health', 'care', 'law', 'supreme', 'court', '\\n', 'words', '’s', 'exactly', 'goto', 'source', 'objectivity', '\\n', 'still', 'dug', 'substance', 'claim', 'law', 'cost', 'hundreds', 'thousands', 'private', 'jobs', 'recent', 'check', 'jobkilling', 'claim', 'several', 'skeptical', 'experts', 'told', 'us', 'impact', 'would', 'big', 'pointing', 'employer', 'payments', 'law', 'small', 'nfib', '’s', 'research', 'n’t', 'factor', 'new', 'tax', 'credits', 'law', 'small', 'businesses', 'would', 'actually', 'lead', 'savings', 'premium', 'contributions', '\\n', 'rhetorical', 'hysteria', 'explicit', 'term', '‘', 'job', 'killer', '’', 'enough', 'make', 'one', 'despair', 'rational', 'public', 'debate', 'said', 'henry', 'aaron', 'senior', 'fellow', 'brookings', 'institution', 'february', 'email', 'politifact', '\\n', 'like', 'cbo', 'w', 'e’ve', 'cautioned', 'discussion', 'law', 'wo', 'n’t', 'mostly', 'based', 'speculation', 'even', 'parts', 'law', 'go', 'effect', '2014', 'barring', 'supreme', 'court', 'action', 'wo', 'n’t', 'know', 'drastic', 'effect', 'jobs', 'years', 'follow', '\\n', 'friends', 'factcheckorg', 'arrived', 'conclusions', 'jobkilling', 'threat', 'january', '2011', '\\n', 'scott', 'could', 'cite', 'new', 'compelling', 'evidence', 'wellworn', 'claim', '\\n', '’s', 'prediction', 'based', 'conversations', 'business', 'owners', 'job', 'creators', 'spokesman', 'brian', 'burgess', 'wrote', 'email', '\\n', 'n’t', 'elaborate', '\\n', 'analyzing', 'truthfulness', 'predictions', 'tricky', 'business', 'normally', 'prefer', 'delve', 'jobkilling', 'claim', 'widely', 'spread', 'carry', 'proof', '\\n', 'scott', '’s', 'spokesman', 'said', 'prediction', 'based', 'anecdotal', 'conversations', 'business', 'owners', 'say', '’s', 'one', 'steeped', 'credible', 'independent', 'evidence', ' ', '’s', 'like', 'scare', 'tactic', 'rule', 'claim', 'false'], 'label': '1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDg0s0AOfr1v",
        "outputId": "0b123158-9159-47fd-f279-9508bc92ae16"
      },
      "source": [
        "test_data = data.TabularDataset(\n",
        "        path= data_path + \"fnn_test_clean.csv\", \n",
        "        format=\"CSV\", \n",
        "        fields=fields,\n",
        "        skip_header=True)\n",
        "\n",
        "print(vars(test_data.examples[1]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['abcs', 'week', 'chairmen', 'republican', 'democratic', ' ', 'national', 'parties', 'debated', 'significance', 'republican', 'charles', 'djous', ' ', 'victory', 'hawaii', 'congressional', 'special', 'election', 'may', '22', '2010', ' ', ' ', 'first', 'time', 'republican', 'represent', 'hawaii', 'congress', 'since', '1991', '\\n', 'rnc', ' ', 'chairman', 'michael', 'steele', 'called', 'victory', 'significant', 'given', 'hawaiis', ' ', 'penchant', 'supporting', 'democrats', 'noted', 'state', ' ', 'birthplace', 'president', 'barack', 'obama', 'sorry', 'birthers', '\\n', ' ', 'course', 'dnc', 'chairman', 'tim', 'kaine', 'different', 'read', 'said', 'djous', ' ', 'victory', 'unique', 'circumstances', 'special', 'election', ' ', 'called', 'replace', 'resigning', 'rep', 'neil', 'abercrombie', 'regular', 'fall', 'election', '   ', 'political', 'mood', 'swing', 'hawaii', 'special', 'election', ' ', 'include', 'primary', 'meant', 'parties', 'could', 'field', 'multiple', 'candidates', ' ', 'three', 'main', 'contenders', 'two', 'democrats', 'djou', 'lone', ' ', 'republican', 'little', '40', 'percent', 'overall', 'vote', '\\n', ' ', 'november', 'election', 'one', 'democrat', 'one', 'republican', ' ', 'feel', 'confident', 'winning', 'race', 'kaine', 'said', '\\n', ' ', 'steele', 'countered', 'hawaii', 'nt', 'history', 'throwing', 'incumbents', ' ', 'office', '\\n', 'obvious', 'fact', 'incumbents', ' ', 'easier', 'road', 'reelection', 'challengers', 'since', '1964', 'less', '85', ' ', 'percent', 'incumbents', 'returned', 'us', 'house', 'according', ' ', 'center', 'responsive', 'politics', 'since', '1998', 'incumbents', ' ', 'reelection', 'rate', 'hovered', '94', '98', 'percent', 'house', ' ', 'numbers', 'senate', 'little', 'lower', ' ', '79', '96', 'percent', ' ', 'elections', 'since', '1998', '\\n', 'incumbents', 'even', 'easier', ' ', 'time', 'getting', 'reelected', 'americas', 'youngest', 'state', '\\n', 'since', 'hawaii', ' ', 'nt', 'incorporated', 'state', '1959', 'nt', 'lot', 'history', ' ', 'examine', 'since', 'hawaii', 'four', 'members', 'congress', 'two', ' ', 'senators', 'two', 'members', 'us', 'house', 'relatively', ' ', 'elections', 'scour', '\\n', 'fact', '5', 'people', 'represented', ' ', 'state', 'us', 'senate', 'two', 'sitting', 'senators', 'democrats', 'daniel', ' ', 'inouye', 'daniel', 'akaka', 'three', 'others', ' ', 'republican', 'hiram', 'fong', ' ', 'democrat', 'spark', 'matsunaga', 'democrat', 'oren', 'e', 'long', 'none', 'lost', ' ', 'reelection', 'campaign', 'senate', ' ', 'fong', 'long', 'retired', ' ', 'matsunaga', 'died', 'office', '\\n', 'hawaiis', 'two', 'congressional', 'house', ' ', 'districts', 'created', '1971', 'previously', 'seats', 'elected', ' ', 'large', '\\n', 'djou', 'represent', 'hawaiis', '1st', 'district', 'second', ' ', 'republican', 'ever', 'replaces', 'abercrombie', '10term', ' ', 'democrat', 'resigned', 'run', 'governor', 'states', '2nd', 'district', ' ', 'never', 'elected', 'republican', '\\n', 'incumbents', 'lost', '\\n', ' ', 'really', '\\n', '2nd', 'district', 'patsy', 'mink', 'daniel', 'akaka', 'ed', 'case', ' ', 'resigned', 'retired', 'order', 'run', 'another', 'office', 'mink', ' ', 'eventually', 'reelected', 'us', 'house', 'died', 'office', '\\n', ' ', '1st', 'district', 'spark', 'matsunaga', 'cecil', 'heftel', 'pat', 'saiki', ' ', 'abercrombie', 'also', 'resigned', 'run', 'another', 'office', '\\n', ' ', 'one', 'asterisk', 'abercrombie', 'first', 'elected', 'congress', '1986', ' ', 'special', 'election', 'like', 'djou', 'though', 'special', 'election', ' ', 'lost', 'partys', 'primary', 'run', 'full', 'twoyear', 'term', ' ', 'day', '\\n', 'counted', 'found', '50', 'elections', ' ', 'incumbent', 'hawaii', 'ballot', 'closest', 'anyone', 'got', 'losing', ' ', 'abercrombie', '1986', 'nt', 'actually', 'incumbent', ' ', 'lost', 'democratic', 'primary', '\\n', 'depending', 'count', ' ', 'puts', 'reelection', 'rate', 'hawaii', '98', 'percent', '100', 'percent', ' ', 'higher', 'national', 'average', 'period', '\\n', 'though', ' ', 'steele', 'talking', 'federal', 'races', 'also', 'checked', 'see', ' ', 'incumbent', 'hawaii', 'governor', 'ever', 'lost', 'bid', 'reelection', 'happened', ' ', 'since', 'hawaii', 'became', 'state', '1962', 'republican', 'william', 'quinn', ' ', 'lost', 'democrat', 'john', 'burns', '\\n', 'back', 'statement', 'rnc', ' ', 'chairman', 'steele', 'said', 'hawaiians', 'nt', 'history', ' ', 'throwing', 'incumbents', 'office', 'said', 'djous', 'election', ' ', 'congress', 'may', 'means', 'republicans', 'good', 'shot', 'keeping', ' ', 'seat', 'november', 'business', 'predicting', ' ', 'outcome', 'house', 'races', 'incumbent', 'ever', 'lost', 'november', ' ', 'congressional', 'election', 'hawaii'], 'label': '0'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLF5UXWy_wu2",
        "outputId": "0c800ab8-7fe8-4139-ca97-38ac512c560f"
      },
      "source": [
        "valid_data = data.TabularDataset(\n",
        "        path= data_path + \"fnn_val_clean.csv\", \n",
        "        format=\"CSV\", \n",
        "        fields=fields,\n",
        "        skip_header=True)\n",
        "\n",
        "print(vars(test_data.examples[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['abcs', 'week', 'chairmen', 'republican', 'democratic', ' ', 'national', 'parties', 'debated', 'significance', 'republican', 'charles', 'djous', ' ', 'victory', 'hawaii', 'congressional', 'special', 'election', 'may', '22', '2010', ' ', ' ', 'first', 'time', 'republican', 'represent', 'hawaii', 'congress', 'since', '1991', '\\n', 'rnc', ' ', 'chairman', 'michael', 'steele', 'called', 'victory', 'significant', 'given', 'hawaiis', ' ', 'penchant', 'supporting', 'democrats', 'noted', 'state', ' ', 'birthplace', 'president', 'barack', 'obama', 'sorry', 'birthers', '\\n', ' ', 'course', 'dnc', 'chairman', 'tim', 'kaine', 'different', 'read', 'said', 'djous', ' ', 'victory', 'unique', 'circumstances', 'special', 'election', ' ', 'called', 'replace', 'resigning', 'rep', 'neil', 'abercrombie', 'regular', 'fall', 'election', '   ', 'political', 'mood', 'swing', 'hawaii', 'special', 'election', ' ', 'include', 'primary', 'meant', 'parties', 'could', 'field', 'multiple', 'candidates', ' ', 'three', 'main', 'contenders', 'two', 'democrats', 'djou', 'lone', ' ', 'republican', 'little', '40', 'percent', 'overall', 'vote', '\\n', ' ', 'november', 'election', 'one', 'democrat', 'one', 'republican', ' ', 'feel', 'confident', 'winning', 'race', 'kaine', 'said', '\\n', ' ', 'steele', 'countered', 'hawaii', 'nt', 'history', 'throwing', 'incumbents', ' ', 'office', '\\n', 'obvious', 'fact', 'incumbents', ' ', 'easier', 'road', 'reelection', 'challengers', 'since', '1964', 'less', '85', ' ', 'percent', 'incumbents', 'returned', 'us', 'house', 'according', ' ', 'center', 'responsive', 'politics', 'since', '1998', 'incumbents', ' ', 'reelection', 'rate', 'hovered', '94', '98', 'percent', 'house', ' ', 'numbers', 'senate', 'little', 'lower', ' ', '79', '96', 'percent', ' ', 'elections', 'since', '1998', '\\n', 'incumbents', 'even', 'easier', ' ', 'time', 'getting', 'reelected', 'americas', 'youngest', 'state', '\\n', 'since', 'hawaii', ' ', 'nt', 'incorporated', 'state', '1959', 'nt', 'lot', 'history', ' ', 'examine', 'since', 'hawaii', 'four', 'members', 'congress', 'two', ' ', 'senators', 'two', 'members', 'us', 'house', 'relatively', ' ', 'elections', 'scour', '\\n', 'fact', '5', 'people', 'represented', ' ', 'state', 'us', 'senate', 'two', 'sitting', 'senators', 'democrats', 'daniel', ' ', 'inouye', 'daniel', 'akaka', 'three', 'others', ' ', 'republican', 'hiram', 'fong', ' ', 'democrat', 'spark', 'matsunaga', 'democrat', 'oren', 'e', 'long', 'none', 'lost', ' ', 'reelection', 'campaign', 'senate', ' ', 'fong', 'long', 'retired', ' ', 'matsunaga', 'died', 'office', '\\n', 'hawaiis', 'two', 'congressional', 'house', ' ', 'districts', 'created', '1971', 'previously', 'seats', 'elected', ' ', 'large', '\\n', 'djou', 'represent', 'hawaiis', '1st', 'district', 'second', ' ', 'republican', 'ever', 'replaces', 'abercrombie', '10term', ' ', 'democrat', 'resigned', 'run', 'governor', 'states', '2nd', 'district', ' ', 'never', 'elected', 'republican', '\\n', 'incumbents', 'lost', '\\n', ' ', 'really', '\\n', '2nd', 'district', 'patsy', 'mink', 'daniel', 'akaka', 'ed', 'case', ' ', 'resigned', 'retired', 'order', 'run', 'another', 'office', 'mink', ' ', 'eventually', 'reelected', 'us', 'house', 'died', 'office', '\\n', ' ', '1st', 'district', 'spark', 'matsunaga', 'cecil', 'heftel', 'pat', 'saiki', ' ', 'abercrombie', 'also', 'resigned', 'run', 'another', 'office', '\\n', ' ', 'one', 'asterisk', 'abercrombie', 'first', 'elected', 'congress', '1986', ' ', 'special', 'election', 'like', 'djou', 'though', 'special', 'election', ' ', 'lost', 'partys', 'primary', 'run', 'full', 'twoyear', 'term', ' ', 'day', '\\n', 'counted', 'found', '50', 'elections', ' ', 'incumbent', 'hawaii', 'ballot', 'closest', 'anyone', 'got', 'losing', ' ', 'abercrombie', '1986', 'nt', 'actually', 'incumbent', ' ', 'lost', 'democratic', 'primary', '\\n', 'depending', 'count', ' ', 'puts', 'reelection', 'rate', 'hawaii', '98', 'percent', '100', 'percent', ' ', 'higher', 'national', 'average', 'period', '\\n', 'though', ' ', 'steele', 'talking', 'federal', 'races', 'also', 'checked', 'see', ' ', 'incumbent', 'hawaii', 'governor', 'ever', 'lost', 'bid', 'reelection', 'happened', ' ', 'since', 'hawaii', 'became', 'state', '1962', 'republican', 'william', 'quinn', ' ', 'lost', 'democrat', 'john', 'burns', '\\n', 'back', 'statement', 'rnc', ' ', 'chairman', 'steele', 'said', 'hawaiians', 'nt', 'history', ' ', 'throwing', 'incumbents', 'office', 'said', 'djous', 'election', ' ', 'congress', 'may', 'means', 'republicans', 'good', 'shot', 'keeping', ' ', 'seat', 'november', 'business', 'predicting', ' ', 'outcome', 'house', 'races', 'incumbent', 'ever', 'lost', 'november', ' ', 'congressional', 'election', 'hawaii'], 'label': '0'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "il4JBh0wwbBK"
      },
      "source": [
        "import random\n",
        "\n",
        "(train_data, valid_data, test_data)=news_data.split(split_ratio=[0.6,0.2,0.2], random_state = random.seed(SEED))\n",
        "\n",
        "# (len(train_data),len(valid_data))\n",
        "# train_data = news_data"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owd14QC4wts9"
      },
      "source": [
        "vocab_size = 25000\n",
        "\n",
        "#For 300D GloVe\n",
        "# TEXT.build_vocab(train_data, max_size = vocab_size, vectors = \"glove.42B.300d\", unk_init = torch.Tensor.normal_)  \n",
        "\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = vocab_size, vectors = \"glove.6B.100d\", unk_init = torch.Tensor.normal_)  \n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "#No. of unique tokens in text\n",
        "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
        "\n",
        "#No. of unique tokens in label\n",
        "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
        "\n",
        "#Commonly used words\n",
        "print(TEXT.vocab.freqs.most_common(10))  \n",
        "\n",
        "#Word dictionary\n",
        "# print(TEXT.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9flK9qFtw0ly"
      },
      "source": [
        "#set batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "#Load an iterator\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch=True,\n",
        "    device = device)\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doFsTUjIcTak"
      },
      "source": [
        "import torch.nn as nn\n",
        "class FakeNewsANN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim)\n",
        "        self.fc = nn.Linear(embed_dim, output_dim)\n",
        "        #activation function\n",
        "        # Uncomment if Loss function is not BCEWithLogitsLoss\n",
        "        # self.act = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        embedded = self.embedding(text)\n",
        "        dense_outputs = self.fc(embedded)\n",
        "        #Final activation function\n",
        "        # Uncomment if Loss function is not BCEWithLogitsLoss\n",
        "        # outputs=self.act(dense_outputs)\n",
        "        \n",
        "        return dense_outputs        "
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB74W3m0dCj6"
      },
      "source": [
        "#define hyperparameters\n",
        "size_of_vocab = len(TEXT.vocab)\n",
        "embedding_dim = 100 \n",
        "# 100\n",
        "\n",
        "dropout = 0.2\n",
        "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "#instantiate the model\n",
        "model = FakeNewsANN(size_of_vocab, embedding_dim, num_output_nodes)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCnze4lpN5kC",
        "outputId": "18ccfbef-bab1-4704-84e9-db988a32f1a3"
      },
      "source": [
        "#architecture\n",
        "print(model)\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The LSTM model has {count_parameters(model):,} trainable parameters')\n",
        "\n",
        "#Initialize the pretrained embedding\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FakeNewsANN(\n",
            "  (embedding): EmbeddingBag(25002, 100, mode=mean)\n",
            "  (fc): Linear(in_features=100, out_features=1, bias=True)\n",
            ")\n",
            "The LSTM model has 2,500,301 trainable parameters\n",
            "torch.Size([25002, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAlm6oq0beHB"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(embedding_dim)\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4y8YDfAOUNb"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    # #round predictions to the closest in\n",
        "    # rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    \n",
        "    # correct = (rounded_preds == y).float() \n",
        "    # acc = correct.sum() / len(correct)\n",
        "    # return acc\n",
        "    precision,recall,fscore,support=score(y,preds,average='micro')\n",
        "    return fscore\n",
        "    \n",
        "#push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA8f-7p8OeSM"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    y_pred = []\n",
        "    y_true = []   \n",
        "    threshold=0.5\n",
        "\n",
        "    #initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        #resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        #retrieve text and no. of words\n",
        "        text, text_lengths = batch.text   \n",
        "        labels = batch.label\n",
        "        #convert to 1D tensor\n",
        "        predictions = model(text, text_lengths).squeeze(1)  \n",
        "        # predictions = model(batch.text).squeeze(1)  \n",
        "        \n",
        "        #compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        #compute the binary accuracy\n",
        "        # acc = binary_accuracy(predictions, batch.label)   \n",
        "        output = (predictions > threshold).int()\n",
        "        y_pred.extend(output.tolist())\n",
        "        y_true.extend(labels.tolist())        \n",
        "        #backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        #update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        #loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        # epoch_acc += acc.item()    \n",
        "    epoch_acc = binary_accuracy(y_pred, y_true) \n",
        "    return epoch_loss / len(iterator), epoch_acc"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRHpi76GO0yt"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    y_pred = []\n",
        "    y_true = []    \n",
        "    threshold=0.5\n",
        "\n",
        "    #initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    #deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            #retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "            labels = batch.label\n",
        "            #convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            # predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            # acc = binary_accuracy(predictions, batch.label)\n",
        "            output = (predictions > threshold).int()\n",
        "            y_pred.extend(output.tolist())\n",
        "            y_true.extend(labels.tolist())        \n",
        "\n",
        "            #keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            # epoch_acc += acc.item()\n",
        "    epoch_acc = binary_accuracy(y_pred, y_true)     \n",
        "    return epoch_loss / len(iterator), epoch_acc"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T14YrEEqO5he",
        "outputId": "117adf38-001b-42d9-b809-86f7fc15ab7b"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "best_valid_acc = float('inf')\n",
        "best_train_acc = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    #train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    #evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    #evaluate the model\n",
        "    # valid_loss, valid_acc = train(model, valid_iterator, optimizer, criterion)\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        best_valid_acc = valid_acc\n",
        "        best_train_acc = train_acc\n",
        "        torch.save(model.state_dict(), data_path + 'saved_fnn_weights_ffn_100d.pt')\n",
        "    \n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.683 | Train Acc: 50.16%\n",
            "\t Val. Loss: 0.668 |  Val. Acc: 50.97%\n",
            "\tTrain Loss: 0.658 | Train Acc: 52.22%\n",
            "\t Val. Loss: 0.643 |  Val. Acc: 55.50%\n",
            "\tTrain Loss: 0.632 | Train Acc: 57.82%\n",
            "\t Val. Loss: 0.624 |  Val. Acc: 59.65%\n",
            "\tTrain Loss: 0.606 | Train Acc: 61.97%\n",
            "\t Val. Loss: 0.610 |  Val. Acc: 60.11%\n",
            "\tTrain Loss: 0.582 | Train Acc: 64.60%\n",
            "\t Val. Loss: 0.598 |  Val. Acc: 63.26%\n",
            "\tTrain Loss: 0.555 | Train Acc: 67.49%\n",
            "\t Val. Loss: 0.590 |  Val. Acc: 66.12%\n",
            "\tTrain Loss: 0.528 | Train Acc: 71.38%\n",
            "\t Val. Loss: 0.582 |  Val. Acc: 64.67%\n",
            "\tTrain Loss: 0.499 | Train Acc: 73.78%\n",
            "\t Val. Loss: 0.577 |  Val. Acc: 66.28%\n",
            "\tTrain Loss: 0.470 | Train Acc: 77.12%\n",
            "\t Val. Loss: 0.573 |  Val. Acc: 67.20%\n",
            "\tTrain Loss: 0.441 | Train Acc: 79.39%\n",
            "\t Val. Loss: 0.573 |  Val. Acc: 68.32%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "Z9vputH9gLRZ",
        "outputId": "c8143177-7cca-4cb6-c259-164d250305c9"
      },
      "source": [
        "# Test Function\n",
        "\n",
        "def test(model, iterator, threshold=0.5):\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "        \n",
        "            #retrieve text and no. of words\n",
        "            text, text_lengths = batch.text\n",
        "            labels = batch.label\n",
        "\n",
        "            #convert to 1d tensor\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "\n",
        "            output = (predictions > threshold).int()\n",
        "            y_pred.extend(output.tolist())\n",
        "            y_true.extend(labels.tolist())\n",
        "    \n",
        "    print('Classification Report:')\n",
        "    print(classification_report(y_true, y_pred, labels=[0,1], digits=4))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
        "\n",
        "    ax.set_title('Confusion Matrix')\n",
        "\n",
        "    ax.set_xlabel('Predicted Labels')\n",
        "    ax.set_ylabel('True Labels')\n",
        "\n",
        "    ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
        "    ax.yaxis.set_ticklabels(['FAKE', 'REAL'])\n",
        "    \n",
        "    \n",
        "path= data_path + 'saved_fnn_weights_ffn_100d.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "test(model, test_iterator)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6514    0.7931    0.7153      1503\n",
            "           1     0.7434    0.5854    0.6550      1539\n",
            "\n",
            "    accuracy                         0.6880      3042\n",
            "   macro avg     0.6974    0.6893    0.6852      3042\n",
            "weighted avg     0.6979    0.6880    0.6848      3042\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}